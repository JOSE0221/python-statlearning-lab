{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2158f6",
   "metadata": {},
   "source": [
    "### Looping through Paths\n",
    "\n",
    "Send me your Jupyter Notebook to my email (jose.perez.castellanos@itam.mx) in the following format: hw1_name_surname.ipynb. Make sure to copy the whole 'assignment1' folder to your local repository or computer and use relative paths, as we have seen in class. I should be able to run all your codes without changing the paths and just saving your file in the same path structure.\n",
    "\n",
    "e.g: '../data/input/file.xlsx'\n",
    "\n",
    "\n",
    "#### Overall Instructions:\n",
    "\n",
    "For the first assignment we will be aggregating reports that were sent daily to AfricaCheck with the most viral posts from Facebook and Twitter. These reports are divided into several files, which you can check out in the data folder. We are going to append each one of these reports, to obtain a final data set with all the posts sent over the time period.\n",
    "\n",
    "We have three different types of reports: Facebook data, Viral Content in Twitter data and Facebook Top Posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd3657",
   "metadata": {},
   "source": [
    "#### 1) Setting up the list of dates:\n",
    "\n",
    "1.1) Before jumping into coding, take a look at the folders and files provided to you. Add a brief description of the organization of these folders, what type of files you have available, the names, variables etc. Whatever you think will help you work with these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfcffc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76db17eb",
   "metadata": {},
   "source": [
    "1.2) Import the file 'dates_experiment.xlsx' located in 'data/input/' folder. Use the function .head() to take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b298a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70d45638",
   "metadata": {},
   "source": [
    "1.2) Notice that the dates in this file go from 20/06/2022 to 14/12/2022 including weekends. The reports were only sent from 2022-10-16 to 2022-10-27, from Sunday to Thursday. \n",
    "\n",
    "- Filter the data frame to the dates when the report was sent. \n",
    "- Create a list with the dates of the report.\n",
    "\n",
    "Hint: when working with dates, Python will understand that you would like to keep anything before certain date x by using the following condition: df['date'] < 'x'\n",
    "Hint: Use the weekday() function to filter the Data Frame by day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d50a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "301c16a2",
   "metadata": {},
   "source": [
    "1.3) EXTRA POINT: Build a function that:\n",
    "\n",
    "- Takes as input a data frame, the name of the column with the dates, a start and a final date.\n",
    "- Filters the data frame by those two dates.\n",
    "- Returns a list with the filtered dates.\n",
    "- Prove that it works by repeating the exercise from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfded7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5f72630",
   "metadata": {},
   "source": [
    "#### 2) Aggregating Facebook\n",
    "\n",
    "2.1) Notice that in each folder there is a file named 'facebook.xlsx'. Loop through these folders using the list you just created, import the 'facebook.xlsx' files and append them one in top of the other to generate an aggregated data set with all the posts from this report sent over this period of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2c349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ccd4160",
   "metadata": {},
   "source": [
    "2.2) Create a folder named '../data/facebook_out/' using the os package as seen in the notes (do not forget to define the function) and export the aggregated data set there as parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d8de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86c26905",
   "metadata": {},
   "source": [
    "#### 3) Viral Content from Twitter\n",
    "\n",
    "3.1) Notice that in each folder there are two files named 'viral_content_twitter_verifiable.xlsx' and 'viral_content_twitter_not_verifiable.xlsx'. \n",
    "\n",
    "- Loop through these folders using the dates list and the type list provided already to you on the cell below.\n",
    "- Import the files and add a column named 'verifiability' which will be a dummy that is 1 if the report is 'verifiable' and 0 if 'not_verifiable'. Hint: add an if-else to your for loop with a condition that uses the type of file in which you are looping.\n",
    "- Append them one on top of the other to generate an aggregated data set with all the posts from this report sent over this period of time:\n",
    "\n",
    "Hint: Do a nested loop across both lists, only two fors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = ['verifiable', 'not_verifiable']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da20fea",
   "metadata": {},
   "source": [
    "3.2) Create a folder named '../data/twitter_out/' using the os package as seen in the notes and export the aggregated data set there as parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ece072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5deb7a49",
   "metadata": {},
   "source": [
    "#### 3) Extra Point: Triple Nested For Loop\n",
    "\n",
    "###### Facebook Top Posts\n",
    "\n",
    "3.1) Notice that in each folder there are 6 files named 'facebook_top_posts_{country}_verifiable.xlsx' and 'facebook_top_posts_{country}_not_verifiable.xlsx', where country are KE (Kenya), ZA (South Africa) and NG (Nigeria)\n",
    "\n",
    "- Loop through these folders using the dates list, the type list and the country list provided already to you.\n",
    "- Import the files and add a column named 'verifiability' which will be a dummy that is 1 if the report is 'verifiable' and 0 if 'not_verifiable', and a column with the country from which this report is from.\n",
    "- Append them one on top of the other to generate an aggregated data set with all the posts from this report sent over this period of time:\n",
    "\n",
    "Hint: Do a nested loop across three lists, with 3 nested fors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = ['verifiable', 'not_verifiable']\n",
    "country = ['KE', 'ZA', 'NG']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
