{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3f6bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Collecting scrapy\n",
      "  Using cached Scrapy-2.12.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Twisted>=21.7.0 (from scrapy)\n",
      "  Using cached twisted-24.11.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting cryptography>=37.0.0 (from scrapy)\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Using cached cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Using cached itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Downloading parsel-1.10.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyOpenSSL>=22.0.0 (from scrapy)\n",
      "  Downloading pyOpenSSL-25.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Using cached queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Using cached service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Using cached w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Using cached zope.interface-7.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (44 kB)\n",
      "Collecting protego>=0.1.15 (from scrapy)\n",
      "  Downloading Protego-0.4.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Using cached itemadapter-0.10.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from scrapy) (24.2)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Using cached tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting lxml>=4.6.0 (from scrapy)\n",
      "  Using cached lxml-5.3.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.8 kB)\n",
      "Collecting defusedxml>=0.7.1 (from scrapy)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Using cached PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=37.0.0->scrapy)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9 in ./venv/lib/python3.12/site-packages (from pyOpenSSL>=22.0.0->scrapy) (4.12.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in ./venv/lib/python3.12/site-packages (from service-identity>=18.1.0->scrapy) (24.3.0)\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->scrapy)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting automat>=24.8.0 (from Twisted>=21.7.0->scrapy)\n",
      "  Using cached Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting constantly>=15.1 (from Twisted>=21.7.0->scrapy)\n",
      "  Using cached constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=21.7.0->scrapy)\n",
      "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting incremental>=24.7.0 (from Twisted>=21.7.0->scrapy)\n",
      "  Using cached incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from zope.interface>=5.1.0->scrapy) (75.8.0)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from tldextract->scrapy) (3.10)\n",
      "Requirement already satisfied: requests>=2.1.0 in ./venv/lib/python3.12/site-packages (from tldextract->scrapy) (2.32.3)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Using cached requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract->scrapy)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=37.0.0->scrapy)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (2024.12.14)\n",
      "Using cached Scrapy-2.12.0-py2.py3-none-any.whl (311 kB)\n",
      "Downloading cryptography-44.0.0-cp39-abi3-macosx_10_9_universal2.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached itemadapter-0.10.0-py3-none-any.whl (11 kB)\n",
      "Using cached itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
      "Using cached lxml-5.3.0-cp312-cp312-macosx_10_9_universal2.whl (8.2 MB)\n",
      "Downloading parsel-1.10.0-py2.py3-none-any.whl (17 kB)\n",
      "Downloading Protego-0.4.0-py2.py3-none-any.whl (8.6 kB)\n",
      "Using cached PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading pyOpenSSL-25.0.0-py3-none-any.whl (56 kB)\n",
      "Using cached queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached twisted-24.11.0-py3-none-any.whl (3.2 MB)\n",
      "Using cached w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached zope.interface-7.2-cp312-cp312-macosx_11_0_arm64.whl (209 kB)\n",
      "Using cached tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
      "Using cached Automat-24.8.1-py3-none-any.whl (42 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Using cached incremental-24.7.2-py3-none-any.whl (20 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: PyDispatcher, zope.interface, w3lib, queuelib, pycparser, pyasn1, protego, lxml, jmespath, itemadapter, incremental, hyperlink, filelock, defusedxml, cssselect, constantly, automat, Twisted, requests-file, pyasn1-modules, parsel, cffi, tldextract, itemloaders, cryptography, service-identity, pyOpenSSL, scrapy\n",
      "Successfully installed PyDispatcher-2.0.7 Twisted-24.11.0 automat-24.8.1 cffi-1.17.1 constantly-23.10.4 cryptography-44.0.0 cssselect-1.2.0 defusedxml-0.7.1 filelock-3.17.0 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.10.0 itemloaders-1.3.2 jmespath-1.0.1 lxml-5.3.0 parsel-1.10.0 protego-0.4.0 pyOpenSSL-25.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycparser-2.22 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.12.0 service-identity-24.2.0 tldextract-5.1.3 w3lib-2.2.1 zope.interface-7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d23437",
   "metadata": {},
   "source": [
    "### Scrapy Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c477e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scrapy import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/scrapy/selector/unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<div id=\"fecha-evento\">\\t    \\r\\n\\t\\t\\t\\t12 de enero de 2024<br>De 8.00 a 15.30 h                </div>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://eventos.itam.mx/es/evento/seminario-de-perspectivas-economicas-2024'\n",
    "html = requests.get(url).content\n",
    "\n",
    "sel = Selector(text = html)\n",
    "fecha = sel.xpath('//div[@id=\"fecha-evento\"]').extract() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43910620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12 de enero de 2024 De 8.00 a 15.30 h'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_string(input_string):\n",
    "    # Remove everything inside '<>'\n",
    "    cleaned_string = re.sub(r'<[^>]+>', ' ', input_string)\n",
    "    \n",
    "    # Remove '\\' and the letter right next to it\n",
    "    cleaned_string = re.sub(r'\\\\.', '', cleaned_string)\n",
    "    \n",
    "    # Remove any double spaces\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', cleaned_string)\n",
    "    \n",
    "    return cleaned_string.strip()\n",
    "\n",
    "fecha_clean = clean_string(fecha[0])\n",
    "fecha_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a077c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evento = sel.xpath('//div[@id=\"cuerpo-evento\"]//p[@dir=\"ltr\" and not(@class=\"rtecenter\")]').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878d5434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Te invitamos a nuestro tradicional Seminario de Perspectivas Económicas 2024.',\n",
       " '8.00 h – Bienvenida',\n",
       " 'Humberto López, Asociación de Ex Alumnos del ITAM, Presidente',\n",
       " '8.15 h – Inauguración. Palabras del Rector del Instituto Tecnológico',\n",
       " 'Autónomo de México',\n",
       " 'Arturo Fernández, ITAM, Rector',\n",
       " '8.30 h – Conferencia magistral - Perspectivas de las Américas ( Zoom )',\n",
       " 'Ilan Goldfajn, Banco Interamericano de Desarrollo, Presidente',\n",
       " '9.00 h – Mesa de pronósticos',\n",
       " 'Carlos Capistrán, Bank of America, Economista en Jefe para México y Canadá',\n",
       " 'Ernesto Revilla, Citigroup, Economista en Jefe para América Latina',\n",
       " 'Alejandrina Salcedo, Banco de México, Directora General de Investigación Económica',\n",
       " 'Moderador: Miguel Messmacher, ITAM, Director general de la División Académica de Ciencias Sociales',\n",
       " '',\n",
       " '10:00 h – Mesa de escenarios políticos de las elecciones en México',\n",
       " 'Luis Carlos Ugalde, Integralia Consultores, Director General',\n",
       " 'Federico Reyes-Heroles, Transparencia Mexicana, Presidente del Consejo Rector',\n",
       " 'Agustín Basave, Universidad de Monterrey, Director del Instituto de Estudios Políticos de la Universidad de Monterrey',\n",
       " 'Moderadora: Alexandra Uribe, ITAM , Directora de la Licenciatura en Ciencia Política',\n",
       " '11:00 – Networking',\n",
       " '',\n",
       " '11.30 – Conferencia magistral - Entorno global',\n",
       " 'Alan Stoga, Tallberg Foundation, Presidente',\n",
       " 'Moderadora: Natalia Saltalamacchia, ITAM, Jefa del Departamento Académico de Estudios Internacionales',\n",
       " '12.30 – Mesa Visión de Sectores Innovadores',\n",
       " 'Eduardo Garza T., Frisa , Presidente y Fundador',\n",
       " 'Hans-Joachim Kohlsdorf, Energy to Market , Socio Fundador',\n",
       " 'Marlene Garayzar, Stori , Cofundadora',\n",
       " 'Moderador: Guillermo I. García Alcocer, ITAM, Director de Planeación y Evaluación de Desempeño',\n",
       " '13:30 – Conferencia magistral - Oportunidades de inversión en México',\n",
       " 'Carlos Slim, Fundación Telmex, Presidente',\n",
       " 'Moderador: Por confirmar',\n",
       " '14:30 – Mesa México y el mundo en la perspectiva electoral EEUU',\n",
       " 'Rafael Fernández de Castro, Centro de Estudios México-Estados Unidos UCSD, Director',\n",
       " 'Arturo Sarukhán, Sarukhán y asociados, Presidente',\n",
       " 'Jorge Suárez-Vélez, Allen &amp; Company, Director',\n",
       " 'Moderadora: Ana María Salazar, Grupo Salazar Slack SC, Directora',\n",
       " '15:30 – Clausura',\n",
       " 'Alejandro Hernández, ITAM, Vicerrector',\n",
       " '',\n",
       " 'Registro auditorio cerrado',\n",
       " 'Regístrate aquí para salas alternas',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evento_clean = []\n",
    "for ev in evento:\n",
    "    event = clean_string(ev)\n",
    "    evento_clean.append(event)\n",
    "evento_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a26fe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>moderator</th>\n",
       "      <th>occupation</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Humberto López</td>\n",
       "      <td>0</td>\n",
       "      <td>Asociación de Ex Alumnos del ITAM, Presidente</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arturo Fernández</td>\n",
       "      <td>0</td>\n",
       "      <td>ITAM, Rector</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ilan Goldfajn</td>\n",
       "      <td>0</td>\n",
       "      <td>Banco Interamericano de Desarrollo, Presidente</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carlos Capistrán</td>\n",
       "      <td>0</td>\n",
       "      <td>Bank of America, Economista en Jefe para Méxi...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ernesto Revilla</td>\n",
       "      <td>0</td>\n",
       "      <td>Citigroup, Economista en Jefe para América La...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alejandrina Salcedo</td>\n",
       "      <td>0</td>\n",
       "      <td>Banco de México, Directora General de Investi...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Miguel Messmacher</td>\n",
       "      <td>1</td>\n",
       "      <td>ITAM, Director general de la División Académi...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Luis Carlos Ugalde</td>\n",
       "      <td>0</td>\n",
       "      <td>Integralia Consultores, Director General</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Federico Reyes-Heroles</td>\n",
       "      <td>0</td>\n",
       "      <td>Transparencia Mexicana, Presidente del Consej...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Agustín Basave</td>\n",
       "      <td>0</td>\n",
       "      <td>Universidad de Monterrey, Director del Instit...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alexandra Uribe</td>\n",
       "      <td>1</td>\n",
       "      <td>ITAM , Directora de la Licenciatura en Cienci...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alan Stoga</td>\n",
       "      <td>0</td>\n",
       "      <td>Tallberg Foundation, Presidente</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Natalia Saltalamacchia</td>\n",
       "      <td>1</td>\n",
       "      <td>ITAM, Jefa del Departamento Académico de Estu...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Eduardo Garza T.</td>\n",
       "      <td>0</td>\n",
       "      <td>Frisa , Presidente y Fundador</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hans-Joachim Kohlsdorf</td>\n",
       "      <td>0</td>\n",
       "      <td>Energy to Market , Socio Fundador</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Marlene Garayzar</td>\n",
       "      <td>0</td>\n",
       "      <td>Stori , Cofundadora</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Guillermo I. García Alcocer</td>\n",
       "      <td>1</td>\n",
       "      <td>ITAM, Director de Planeación y Evaluación de ...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Carlos Slim</td>\n",
       "      <td>0</td>\n",
       "      <td>Fundación Telmex, Presidente</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rafael Fernández de Castro</td>\n",
       "      <td>0</td>\n",
       "      <td>Centro de Estudios México-Estados Unidos UCSD...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Arturo Sarukhán</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarukhán y asociados, Presidente</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jorge Suárez-Vélez</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen &amp;amp; Company, Director</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ana María Salazar</td>\n",
       "      <td>1</td>\n",
       "      <td>Grupo Salazar Slack SC, Directora</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Alejandro Hernández</td>\n",
       "      <td>0</td>\n",
       "      <td>ITAM, Vicerrector</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        speaker  moderator  \\\n",
       "0                Humberto López          0   \n",
       "1              Arturo Fernández          0   \n",
       "2                 Ilan Goldfajn          0   \n",
       "3              Carlos Capistrán          0   \n",
       "4               Ernesto Revilla          0   \n",
       "5           Alejandrina Salcedo          0   \n",
       "6             Miguel Messmacher          1   \n",
       "7            Luis Carlos Ugalde          0   \n",
       "8        Federico Reyes-Heroles          0   \n",
       "9                Agustín Basave          0   \n",
       "10              Alexandra Uribe          1   \n",
       "11                   Alan Stoga          0   \n",
       "12       Natalia Saltalamacchia          1   \n",
       "13             Eduardo Garza T.          0   \n",
       "14       Hans-Joachim Kohlsdorf          0   \n",
       "15             Marlene Garayzar          0   \n",
       "16  Guillermo I. García Alcocer          1   \n",
       "17                  Carlos Slim          0   \n",
       "18   Rafael Fernández de Castro          0   \n",
       "19              Arturo Sarukhán          0   \n",
       "20           Jorge Suárez-Vélez          0   \n",
       "21            Ana María Salazar          1   \n",
       "22          Alejandro Hernández          0   \n",
       "\n",
       "                                           occupation  year  \n",
       "0       Asociación de Ex Alumnos del ITAM, Presidente  2024  \n",
       "1                                        ITAM, Rector  2024  \n",
       "2      Banco Interamericano de Desarrollo, Presidente  2024  \n",
       "3    Bank of America, Economista en Jefe para Méxi...  2024  \n",
       "4    Citigroup, Economista en Jefe para América La...  2024  \n",
       "5    Banco de México, Directora General de Investi...  2024  \n",
       "6    ITAM, Director general de la División Académi...  2024  \n",
       "7            Integralia Consultores, Director General  2024  \n",
       "8    Transparencia Mexicana, Presidente del Consej...  2024  \n",
       "9    Universidad de Monterrey, Director del Instit...  2024  \n",
       "10   ITAM , Directora de la Licenciatura en Cienci...  2024  \n",
       "11                    Tallberg Foundation, Presidente  2024  \n",
       "12   ITAM, Jefa del Departamento Académico de Estu...  2024  \n",
       "13                      Frisa , Presidente y Fundador  2024  \n",
       "14                  Energy to Market , Socio Fundador  2024  \n",
       "15                                Stori , Cofundadora  2024  \n",
       "16   ITAM, Director de Planeación y Evaluación de ...  2024  \n",
       "17                       Fundación Telmex, Presidente  2024  \n",
       "18   Centro de Estudios México-Estados Unidos UCSD...  2024  \n",
       "19                   Sarukhán y asociados, Presidente  2024  \n",
       "20                      Allen &amp; Company, Director  2024  \n",
       "21                  Grupo Salazar Slack SC, Directora  2024  \n",
       "22                                  ITAM, Vicerrector  2024  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = [element for element in evento_clean if ',' in element]\n",
    "people_df = pd.DataFrame(people, columns=['name'])\n",
    "people_df['speaker'] = people_df['name'].apply(lambda x: x.split(',')[0].strip())\n",
    "people_df['moderator'] = people_df['speaker'].apply(lambda x: 1 if 'Moderador:' in x or 'Moderadora:' in x else 0)\n",
    "people_df['speaker'] = people_df['speaker'].str.replace('Moderador\\\\:|Moderadora\\\\:', '', regex=True).str.strip()\n",
    "people_df['occupation'] = people_df['name'].str.extract(r',(.*)')\n",
    "people_df['year'] = 2024\n",
    "people_df = people_df.drop(['name'], axis = 1)\n",
    "people_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48754a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_seminario(year):\n",
    "    url = f'https://eventos.itam.mx/es/evento/seminario-de-perspectivas-economicas-{year}'\n",
    "    html = requests.get(url).content\n",
    "    sel = Selector(text = html)\n",
    "    evento = sel.xpath('//div[@id=\"cuerpo-evento\"]//p').extract()\n",
    "    \n",
    "    evento_clean = []\n",
    "    for ev in evento:\n",
    "        event = clean_string(ev)\n",
    "        evento_clean.append(event)\n",
    "    \n",
    "    people = [element for element in evento_clean if ',' in element]\n",
    "    people_df = pd.DataFrame(people, columns=['name'])\n",
    "    people_df = people_df[~people_df['name'].str.contains('Cuota de recuperación\\\\:|reembolso|Perspectives|invitamos|horario|Bienvenida|acompañarnos')]\n",
    "    people_df['speaker'] = people_df['name'].apply(lambda x: x.split(',')[0].strip())\n",
    "    people_df['moderator'] = people_df['speaker'].apply(lambda x: 1 if 'Moderador:' in x or 'Moderadora:' in x\n",
    "                                                        or 'Modera:' in x else 0)\n",
    "    people_df['speaker'] = people_df['speaker'].str.replace('Moderador\\\\:|Moderadora\\\\:|Modera\\\\:',\n",
    "                                                            '', regex=True).str.strip()\n",
    "    people_df['occupation'] = people_df['name'].str.extract(r',(.*)')\n",
    "    people_df['year'] = year\n",
    "    people_df = people_df.drop(['name'], axis = 1)\n",
    "    \n",
    "    return(people_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37feb4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/scrapy/selector/unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/scrapy/selector/unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/scrapy/selector/unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/scrapy/selector/unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/scrapy/selector/unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>moderator</th>\n",
       "      <th>occupation</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arturo Fernández P.</td>\n",
       "      <td>0</td>\n",
       "      <td>ITAM , Rector</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alejandro Díaz de León Carrillo</td>\n",
       "      <td>0</td>\n",
       "      <td>Banco de México, Gobernador</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alejandro Werner Wainfeld</td>\n",
       "      <td>0</td>\n",
       "      <td>FMI, Dir. Depto. del Hemisferio Occidental</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iván Moguel</td>\n",
       "      <td>0</td>\n",
       "      <td>Chévez Ruiz Zamarripa, Socio</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lorenza Martinez</td>\n",
       "      <td>1</td>\n",
       "      <td>Accenture México, Managing Director</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Rafael Fernández de Castro</td>\n",
       "      <td>0</td>\n",
       "      <td>Centro de Estudios México-Estados Unidos UCSD...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Arturo Sarukhán</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarukhán y asociados, Presidente</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Jorge Suárez-Vélez</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen &amp;amp; Company, Director</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Ana María Salazar</td>\n",
       "      <td>1</td>\n",
       "      <td>Grupo Salazar Slack SC, Directora</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Alejandro Hernández</td>\n",
       "      <td>0</td>\n",
       "      <td>ITAM, Vicerrector</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            speaker  moderator  \\\n",
       "0               Arturo Fernández P.          0   \n",
       "1   Alejandro Díaz de León Carrillo          0   \n",
       "2         Alejandro Werner Wainfeld          0   \n",
       "3                       Iván Moguel          0   \n",
       "4                  Lorenza Martinez          1   \n",
       "..                              ...        ...   \n",
       "86       Rafael Fernández de Castro          0   \n",
       "87                  Arturo Sarukhán          0   \n",
       "88               Jorge Suárez-Vélez          0   \n",
       "89                Ana María Salazar          1   \n",
       "90              Alejandro Hernández          0   \n",
       "\n",
       "                                           occupation  year  \n",
       "0                                       ITAM , Rector  2020  \n",
       "1                         Banco de México, Gobernador  2020  \n",
       "2          FMI, Dir. Depto. del Hemisferio Occidental  2020  \n",
       "3                        Chévez Ruiz Zamarripa, Socio  2020  \n",
       "4                 Accenture México, Managing Director  2020  \n",
       "..                                                ...   ...  \n",
       "86   Centro de Estudios México-Estados Unidos UCSD...  2024  \n",
       "87                   Sarukhán y asociados, Presidente  2024  \n",
       "88                      Allen &amp; Company, Director  2024  \n",
       "89                  Grupo Salazar Slack SC, Directora  2024  \n",
       "90                                  ITAM, Vicerrector  2024  \n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.DataFrame()\n",
    "for y in range(2020, 2025):\n",
    "    df = scrape_seminario(y)\n",
    "    df_final = pd.concat([df_final, df]).reset_index(drop=True)\n",
    "    \n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2d7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_excel('../data/seminario_attendees.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2acf22b",
   "metadata": {},
   "source": [
    "### Bots:\n",
    "\n",
    "## Recommendations to run this notebook\n",
    "\n",
    "# Complete Setup Instructions for Python Project\n",
    "\n",
    "## 1. Create a Virtual Environment\n",
    "To isolate your project dependencies:\n",
    "- Open your terminal.\n",
    "- Navigate to your project directory:\n",
    "  ```bash\n",
    "  cd /Users/joseperez/Documents/GitHub/python-statlearning-lab/week_2/code\n",
    "\n",
    "  python3 -m venv venv\n",
    "\n",
    "  source venv/bin/activate #on mac\n",
    "  venv\\Scripts\\activate #on windows\n",
    "\n",
    "  pip install --upgrade pip setuptools wheel\n",
    "\n",
    "  pip install -r requirements.txt\n",
    "\n",
    "  brew install hdf5\n",
    "  pip install h5py\n",
    "\n",
    "  pip install spacy\n",
    "  python -m spacy download en_core_web_sm\n",
    "  python -m spacy download es_core_news_lg\n",
    "  python -m spacy download es_core_news_sm\n",
    "  pip3 install murmurhash\n",
    "\n",
    "Deactivate the Virtual Environment\n",
    "    ```bash\n",
    "    deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470d78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e232b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/joseperez/Downloads/code\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e599d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import selenium\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#s=Service(ChromeDriverManager().install()) #MAC user might need this\n",
    "#driver = webdriver.Chrome(service=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6077226",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=51300): Max retries exceeded with url: /session/06446e73f4d6f706da1b311da578ee0b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x174f24290>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    792\u001b[0m     conn,\n\u001b[1;32m    793\u001b[0m     method,\n\u001b[1;32m    794\u001b[0m     url,\n\u001b[1;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:497\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    498\u001b[0m         method,\n\u001b[1;32m    499\u001b[0m         url,\n\u001b[1;32m    500\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    501\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    502\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    503\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    504\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    505\u001b[0m         enforce_content_length\u001b[38;5;241m=\u001b[39menforce_content_length,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:395\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders()\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1293\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1052\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m \n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:990\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:243\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:218\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x174f24290>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://twitter.com/login\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:363\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/_request_methods.py:118\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    111\u001b[0m         method,\n\u001b[1;32m    112\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[1;32m    119\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m    120\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/_request_methods.py:217\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    213\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    215\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:875\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    874\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    876\u001b[0m         method,\n\u001b[1;32m    877\u001b[0m         url,\n\u001b[1;32m    878\u001b[0m         body,\n\u001b[1;32m    879\u001b[0m         headers,\n\u001b[1;32m    880\u001b[0m         retries,\n\u001b[1;32m    881\u001b[0m         redirect,\n\u001b[1;32m    882\u001b[0m         assert_same_host,\n\u001b[1;32m    883\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    884\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[1;32m    885\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[1;32m    886\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    887\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[1;32m    888\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    889\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    894\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:875\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    874\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    876\u001b[0m         method,\n\u001b[1;32m    877\u001b[0m         url,\n\u001b[1;32m    878\u001b[0m         body,\n\u001b[1;32m    879\u001b[0m         headers,\n\u001b[1;32m    880\u001b[0m         retries,\n\u001b[1;32m    881\u001b[0m         redirect,\n\u001b[1;32m    882\u001b[0m         assert_same_host,\n\u001b[1;32m    883\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    884\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[1;32m    885\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[1;32m    886\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    887\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[1;32m    888\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    889\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    894\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:875\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    874\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    876\u001b[0m         method,\n\u001b[1;32m    877\u001b[0m         url,\n\u001b[1;32m    878\u001b[0m         body,\n\u001b[1;32m    879\u001b[0m         headers,\n\u001b[1;32m    880\u001b[0m         retries,\n\u001b[1;32m    881\u001b[0m         redirect,\n\u001b[1;32m    882\u001b[0m         assert_same_host,\n\u001b[1;32m    883\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    884\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[1;32m    885\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[1;32m    886\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    887\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[1;32m    888\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    889\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    894\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[1;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    846\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    847\u001b[0m )\n\u001b[1;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[1;32m    850\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=51300): Max retries exceeded with url: /session/06446e73f4d6f706da1b311da578ee0b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x174f24290>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "driver.get('http://twitter.com/login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6584d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2bd9d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User join date: Joined February 2021\n"
     ]
    }
   ],
   "source": [
    "# Open the Twitter profile\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://twitter.com/HLarreguy')\n",
    "time.sleep(1)\n",
    "\n",
    "# Find elements with the specified XPath\n",
    "profile = driver.find_elements(By.XPATH, '//span[@data-testid=\"UserJoinDate\"]')\n",
    "\n",
    "# Initialize Date variable\n",
    "Date = None\n",
    "\n",
    "# Extract the text if elements are found\n",
    "if profile:\n",
    "    for p in profile:\n",
    "        Date = p.text  # This will take the text of the last matched element\n",
    "else:\n",
    "    print(\"No elements found with the specified XPath.\")\n",
    "\n",
    "# Print the result or a message if Date remains undefined\n",
    "if Date:\n",
    "    print(\"User join date:\", Date)\n",
    "else:\n",
    "    print(\"Join date not found.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f055e1",
   "metadata": {},
   "source": [
    "## Scraping the Trending Topics of Today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24207d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(f'https://twitter.com/explore/tabs/trending')\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "trend = driver.find_elements(By.XPATH,\n",
    "                             '//div[@data-testid=\"cellInnerDiv\" and not(@style=\"transform: translateY(0px); position: absolute; width: 100%;\")]/div/div/div/div')\n",
    "\n",
    "Name = []\n",
    "posts = []\n",
    "for t in trend:\n",
    "    Name1 = t.find_element(By.XPATH, './/div[@style=\"text-overflow: unset; color: rgb(15, 20, 25);\"]').text\n",
    "    Name.append(Name1)\n",
    "    \n",
    "    posts1 = t.find_element(By.XPATH, './div[3]').text\n",
    "    posts.append(posts1)\n",
    "\n",
    "df = pd.DataFrame(zip(Name, posts), columns=['trend','n_posts'])\n",
    "df.to_excel('../data/trends_18_01_2024.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "582098ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend</th>\n",
       "      <th>n_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#ConClaudiaGanamos</td>\n",
       "      <td>4,291 posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paramore</td>\n",
       "      <td>19.8K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#FelizJueves</td>\n",
       "      <td>10.9K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOY SE ESTRENA BOBO</td>\n",
       "      <td>11.9K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unionistas</td>\n",
       "      <td>33.2K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Milei</td>\n",
       "      <td>768K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andrés Guardado</td>\n",
       "      <td>5,907 posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Davos</td>\n",
       "      <td>816K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balde</td>\n",
       "      <td>14.1K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MAÑANA BOBO EN SPOTIFY</td>\n",
       "      <td>42.7K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kings of Leon</td>\n",
       "      <td>4,050 posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Loret</td>\n",
       "      <td>40.6K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Xavi</td>\n",
       "      <td>45.9K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jorge Sánchez</td>\n",
       "      <td>2,617 posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Toluca</td>\n",
       "      <td>26.7K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vive Latino</td>\n",
       "      <td>1,020 posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SIEMPRE CONTIGO YERI</td>\n",
       "      <td>13.6K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hyuna</td>\n",
       "      <td>36.1K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Epigcerdo</td>\n",
       "      <td>12.9K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>101K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>INAI</td>\n",
       "      <td>14.4K posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Daniel Asaf</td>\n",
       "      <td>36.4K posts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trend      n_posts\n",
       "0       #ConClaudiaGanamos  4,291 posts\n",
       "1                 Paramore  19.8K posts\n",
       "2             #FelizJueves  10.9K posts\n",
       "3      HOY SE ESTRENA BOBO  11.9K posts\n",
       "4               Unionistas  33.2K posts\n",
       "5                    Milei   768K posts\n",
       "6          Andrés Guardado  5,907 posts\n",
       "7                    Davos   816K posts\n",
       "8                    Balde  14.1K posts\n",
       "9   MAÑANA BOBO EN SPOTIFY  42.7K posts\n",
       "10           Kings of Leon  4,050 posts\n",
       "11                   Loret  40.6K posts\n",
       "12                    Xavi  45.9K posts\n",
       "13           Jorge Sánchez  2,617 posts\n",
       "14                  Toluca  26.7K posts\n",
       "15             Vive Latino  1,020 posts\n",
       "16    SIEMPRE CONTIGO YERI  13.6K posts\n",
       "17                   hyuna  36.1K posts\n",
       "18               Epigcerdo  12.9K posts\n",
       "19               Barcelona   101K posts\n",
       "20                    INAI  14.4K posts\n",
       "21             Daniel Asaf  36.4K posts"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d8a1a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll 0\n",
      "Previous: 1, Current: 0\n",
      "Scroll 1\n",
      "Previous: 0, Current: 2500\n",
      "Scroll 2\n",
      "Previous: 2500, Current: 5000\n",
      "Scroll 3\n",
      "Previous: 5000, Current: 7087.5\n",
      "Scroll 4\n",
      "Previous: 7087.5, Current: 7087.5\n",
      "You've reached the end of the page.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to a public Wikipedia page with a long list\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_by_revenue'\n",
    "driver.get(url)\n",
    "\n",
    "# Define scrolling parameters\n",
    "scroll_distance = 2500\n",
    "scroll_pos = [1]  # List to track scroll positions\n",
    "i = 0  # Counter for scroll actions\n",
    "t = 0  # Index tracker for scroll positions\n",
    "\n",
    "# Infinite scroll loop\n",
    "while True:\n",
    "    try:\n",
    "        # Allow time for the page to load\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Get the current scroll position\n",
    "        current_scroll_pos = driver.execute_script(\"return window.scrollY;\")\n",
    "        scroll_pos.append(current_scroll_pos)\n",
    "\n",
    "        # Scroll down by the specified distance\n",
    "        driver.execute_script(f'window.scrollBy(0, {scroll_distance});')\n",
    "        time.sleep(2)  # Allow additional time for dynamic content to load\n",
    "\n",
    "        t += 1\n",
    "        print(f'Scroll {i}')\n",
    "        print(f'Previous: {scroll_pos[t-1]}, Current: {scroll_pos[t]}')\n",
    "\n",
    "        # Check if the end of the page is reached\n",
    "        if scroll_pos[t-1] == scroll_pos[t]:\n",
    "            print(\"You've reached the end of the page.\")\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during scrolling: {e}\")\n",
    "        break\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a558073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "0 2500\n",
      "2500 5000\n",
      "5000 7086.5\n",
      "7086.5 7086.5\n",
      "you've reached the end\n",
      "Scraping completed and saved to 'wikipedia_scrape_results_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to a public Wikipedia page (List of largest companies by revenue)\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_by_revenue'\n",
    "driver.get(url)\n",
    "\n",
    "# Define scrolling parameters\n",
    "scroll_distance = 2500  # Distance to scroll each time\n",
    "scroll_pos = [1]  # Track scroll positions to detect when we reach the end\n",
    "CompanyNames = []  # List to store company names\n",
    "Revenues = []  # List to store revenues\n",
    "Profits = []  # List to store profits\n",
    "\n",
    "# Locate the initial content (rows of the Wikipedia table)\n",
    "articles = driver.find_elements(By.XPATH, \"//table[contains(@class, 'wikitable')]//tr\")\n",
    "\n",
    "# Initialize variables for scrolling logic\n",
    "t = 0  # Counter for scroll attempts\n",
    "\n",
    "# Infinite scroll loop to simulate data scraping\n",
    "while True:\n",
    "    time.sleep(2)  # Allow the page to load\n",
    "\n",
    "    # Get the current scroll position\n",
    "    current_scroll_pos = driver.execute_script(\"return window.scrollY;\")\n",
    "    scroll_pos.append(current_scroll_pos)\n",
    "\n",
    "    # Process visible elements (in this example, table rows)\n",
    "    for article in articles:\n",
    "        try:\n",
    "            # Scrape the company name\n",
    "            CompanyName = article.find_element(By.XPATH, \".//td[1]\").text\n",
    "            CompanyNames.append(CompanyName)\n",
    "        except:\n",
    "            CompanyNames.append(np.nan)  # Handle missing data\n",
    "\n",
    "        try:\n",
    "            # Scrape the revenue (update XPath as per table structure)\n",
    "            Revenue = article.find_element(By.XPATH, \".//td[2]\").text\n",
    "            Revenues.append(Revenue)\n",
    "        except:\n",
    "            Revenues.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            # Scrape the profit (update XPath as per table structure)\n",
    "            Profit = article.find_element(By.XPATH, \".//td[3]\").text\n",
    "            Profits.append(Profit)\n",
    "        except:\n",
    "            Profits.append(np.nan)\n",
    "\n",
    "    # Scroll down by the specified distance\n",
    "    driver.execute_script(f'window.scrollBy(0, {scroll_distance});')\n",
    "    time.sleep(5)  # Allow additional time for dynamic content to load\n",
    "\n",
    "    # Re-fetch visible elements after scrolling\n",
    "    articles = driver.find_elements(By.XPATH, \"//table[contains(@class, 'wikitable')]//tr\")\n",
    "\n",
    "    t += 1  # Increment scroll counter\n",
    "    print(scroll_pos[t-1], scroll_pos[t])  # Print scroll progress\n",
    "\n",
    "    # Check if the end of the page is reached\n",
    "    if scroll_pos[t-1] == scroll_pos[t]:\n",
    "        print(\"you've reached the end\")\n",
    "        break\n",
    "\n",
    "# Create a DataFrame with the scraped data\n",
    "df = pd.DataFrame(zip(CompanyNames, Revenues, Profits),\n",
    "                  columns=['Company Name', 'Revenue', 'Profit'])\n",
    "\n",
    "# Save the DataFrame to a CSV file for analysis\n",
    "df.to_csv('../data/wikipedia_scrape_results_cleaned.csv', index=False)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"Scraping completed and saved to 'wikipedia_scrape_results_cleaned.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f43bfdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citigroup\n",
      "Financials\n",
      "$156,820\n"
     ]
    }
   ],
   "source": [
    "print(df['Company Name'][50])\n",
    "print(df['Revenue'][50])\n",
    "print(df['Profit'][50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8dc678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'Revenue' column to 'Industry'\n",
    "df.rename(columns={'Revenue': 'Industry'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e0201de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Profit' column to numeric (remove any non-numeric characters like '$' and ',')\n",
    "df['Profit'] = df['Profit'].replace('[\\\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52e74b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156820.0\n"
     ]
    }
   ],
   "source": [
    "print(df['Profit'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26b53032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Industry' and calculate statistics\n",
    "industry_summary = df.groupby('Industry').agg({\n",
    "    'Company Name': 'count',       # Number of companies per industry\n",
    "    'Profit': ['sum', 'mean']      # Total and average profit per industry\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "326a1d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Industry  Company Count  Total Profit  \\\n",
      "15                     Oil and gas             40    13476855.0   \n",
      "13                      Healthcare             35     9360695.0   \n",
      "12                      Financials             40     8598375.0   \n",
      "5                       Automotive             35     7735540.0   \n",
      "16                          Retail             15     5354955.0   \n",
      "14          Information technology             15     4679005.0   \n",
      "6                      Commodities             15     4310545.0   \n",
      "8                     Construction             15     3299205.0   \n",
      "17  Retail\\ninformation technology              5     2873925.0   \n",
      "9                      Electricity              5     2729740.0   \n",
      "10                     Electronics             10     1980665.0   \n",
      "7                     Conglomerate             10     1712500.0   \n",
      "18                           Steel              5      786080.0   \n",
      "11                          Energy              5      735500.0   \n",
      "1                               11              5           0.0   \n",
      "4                                4              5           0.0   \n",
      "3                               22              5           0.0   \n",
      "2                                2             10           0.0   \n",
      "0                                1             45           0.0   \n",
      "\n",
      "    Average Profit  \n",
      "15   336921.375000  \n",
      "13   267448.428571  \n",
      "12   214959.375000  \n",
      "5    221015.428571  \n",
      "16   356997.000000  \n",
      "14   311933.666667  \n",
      "6    287369.666667  \n",
      "8    219947.000000  \n",
      "17   574785.000000  \n",
      "9    545948.000000  \n",
      "10   198066.500000  \n",
      "7    171250.000000  \n",
      "18   157216.000000  \n",
      "11   147100.000000  \n",
      "1              NaN  \n",
      "4              NaN  \n",
      "3              NaN  \n",
      "2              NaN  \n",
      "0              NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rename columns for clarity\n",
    "industry_summary.columns = ['Industry', 'Company Count', 'Total Profit', 'Average Profit']\n",
    "\n",
    "# Sort by 'Total Profit' in descending order\n",
    "industry_summary = industry_summary.sort_values(by='Total Profit', ascending=False)\n",
    "\n",
    "# Display the summarized DataFrame\n",
    "print(industry_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
